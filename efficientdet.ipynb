{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0392131",
   "metadata": {},
   "source": [
    "# Training Tensorflow Objecte Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1144d",
   "metadata": {},
   "source": [
    "The most convenient way to train a TensorFlow object detection model is to use verified Tensorflow models architectures provided by TensorFlow. you can find the GitHub repo at this link [TensorFlow official](https://github.com/tensorflow/models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd477f9",
   "metadata": {},
   "source": [
    "In this section, I train an object detection model (EfficientDet D3) in a virtual environment. The reason for using a virtual environment is to make the whole process separate so that it won't affect other model implements or environment setups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad12cad",
   "metadata": {},
   "source": [
    "I use an anaconda virtual environment to train this model. You can use any kind of virtual environment setup to train the model. the benefit of using an anaconda environment is, when I install TensorFlow GPU using conda commands, it automatically install compatible Cuda and Cudnn libraries. if you use other environments, you may or may not have to set up these two necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a3ec5",
   "metadata": {},
   "source": [
    "### Install anaconda virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e764124",
   "metadata": {},
   "source": [
    "installing anaconda is fairly easy. Open a terminal copy-paste the following commands.\n",
    "\n",
    "<pre>\n",
    "sudo apt install libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6\n",
    "\n",
    "wget -P /tmp https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.sh\n",
    "\n",
    "bash /tmp/Anaconda3-2020.02-Linux-x86_64.sh\n",
    "\n",
    "source ~/.bashrc\n",
    "</pre>\n",
    "\n",
    "This process will ask for license approval. just approve the license and you are ready to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a86565",
   "metadata": {},
   "source": [
    "After installing an anaconda-navigator, close the terminal and open a new one. Now create a new anaconda virtual environment. Simple type -\n",
    "<pre>conda create -n tensorflow pip python=3.6</pre>\n",
    "where \"tensorflow\" is the name of your environment. You can choose any python version. I use python 3.6 as I know this version is one of the most stable versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c581f65",
   "metadata": {},
   "source": [
    "After creating the virtual environment activate the environment. Simply type **source activate tensorflow**. The terminal will show you this command once the environment installation is successfully finished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e599d",
   "metadata": {},
   "source": [
    "Next, install TensorFlow-GPU (as we will use GPU to train) on our system. simply type -\n",
    "\n",
    "<pre>conda install -c anaconda tensorflow-gpu</pre>\n",
    "\n",
    "This will install the TensorFlow-GPU version to our system as well as compatible Cuda and Cudnn in this virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517b8a8",
   "metadata": {},
   "source": [
    "That's all for an anaconda virtual environment setup.<br>\n",
    "**Note: all these commands should be run in a terminal, not in the Jupyter notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e4737",
   "metadata": {},
   "source": [
    "## Install TensorFlow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b127eb71",
   "metadata": {},
   "source": [
    "Now open a jupyter notebook for the next installation process that is TensorFlow Object Detection API. Simply type -\n",
    "<pre> jupyter notebook</pre> to open a jupyter notebook.\n",
    "\n",
    "Now you may face some errors as jupyter notebook is not always installed with the new environment setup. If this happens for you simply type - <pre> pip install notebook </pre> This will install a new jupyter notebook for this virtual environment.<br>\n",
    "\n",
    "Now open jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ddf85",
   "metadata": {},
   "source": [
    "First check the installed version of Tensorflow. I installed Tensorflow 2.4.1. Your version might be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e36f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 13:49:37.407858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5dfb44",
   "metadata": {},
   "source": [
    "### Downloading the TensorFlow Model Garden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28bc9c",
   "metadata": {},
   "source": [
    "First create a folder where you like to store all your files(pre-trained model, trained model, data, etc) related to object detection. then go to that directory and execute the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661faf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9407510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 68544, done.\u001b[K\n",
      "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 68544 (delta 2), reused 9 (delta 2), pack-reused 68534\u001b[K\n",
      "Receiving objects: 100% (68544/68544), 576.95 MiB | 14.26 MiB/s, done.\n",
      "Resolving deltas: 100% (48277/48277), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea6a7f",
   "metadata": {},
   "source": [
    "This will download Tensorflow model garden in your folder. I named my model as **\"TensorFlow\"**. You can name anything you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568be29",
   "metadata": {},
   "source": [
    "### Installat Protobuf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7fac9f",
   "metadata": {},
   "source": [
    "Tensorflow Object Detection API uses Protobufs to configure model and training parameters. This library must be installed inside the **\"research\"** folder, which is inside the **\"models\"** folder. BTW, the **\"models\"** folder is the Tensorflow model garden repo which we pulled earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4fcf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-20/Desktop/TensorFlow/models/research\n"
     ]
    }
   ],
   "source": [
    "cd models/research/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb00b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow/models/research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb33de",
   "metadata": {},
   "source": [
    "Now execute the Protobuf installation command here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5b0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c4c7d",
   "metadata": {},
   "source": [
    "### Install COCO API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032f9c9",
   "metadata": {},
   "source": [
    "\"pycocotools\" is another dependency needed for Tensorflow object detection API. You can simply pull the library from GitHub and install/make it. But before doing that, you need \"cython\" library to be installed. Install \"cython\" as follows -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a113e949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cython\n",
      "  Downloading Cython-0.29.26-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: cython\n",
      "Successfully installed cython-0.29.26\n"
     ]
    }
   ],
   "source": [
    "!pip install cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62132a1",
   "metadata": {},
   "source": [
    "Next clone \"pycocotools\" repo from GitHub and execute the following commands one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98922d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cocoapi'...\n",
      "remote: Enumerating objects: 975, done.\u001b[K\n",
      "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
      "Receiving objects: 100% (975/975), 11.72 MiB | 13.58 MiB/s, done.\n",
      "Resolving deltas: 100% (576/576), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cocodataset/cocoapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7329f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-20/Desktop/TensorFlow/models/research/cocoapi/PythonAPI\n"
     ]
    }
   ],
   "source": [
    "cd cocoapi/PythonAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a815beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python setup.py build_ext --inplace\n",
      "running build_ext\n",
      "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
      "/home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /home/ubuntu-20/Desktop/TensorFlow/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'pycocotools._mask' extension\n",
      "gcc -pthread -B /home/ubuntu-20/anaconda3/envs/tensorflow/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/ubuntu-20/anaconda3/envs/tensorflow/include -I/home/ubuntu-20/anaconda3/envs/tensorflow/include -fPIC -O2 -isystem /home/ubuntu-20/anaconda3/envs/tensorflow/include -fPIC -I/home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include -I../common -I/home/ubuntu-20/anaconda3/envs/tensorflow/include/python3.9 -c ../common/maskApi.c -o build/temp.linux-x86_64-3.9/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   46 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
      "      |                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "  166 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "  166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
      "      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "  167 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "  167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
      "      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "  212 |       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "      |       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "  212 |       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
      "      |                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "  220 |   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "      |   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
      "  220 |   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
      "      |                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "  228 |     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "      |     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "  228 |     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
      "      |                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "gcc -pthread -B /home/ubuntu-20/anaconda3/envs/tensorflow/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/ubuntu-20/anaconda3/envs/tensorflow/include -I/home/ubuntu-20/anaconda3/envs/tensorflow/include -fPIC -O2 -isystem /home/ubuntu-20/anaconda3/envs/tensorflow/include -fPIC -I/home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include -I../common -I/home/ubuntu-20/anaconda3/envs/tensorflow/include/python3.9 -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.9/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-3.9\n",
      "creating build/lib.linux-x86_64-3.9/pycocotools\n",
      "gcc -pthread -B /home/ubuntu-20/anaconda3/envs/tensorflow/compiler_compat -shared -Wl,-rpath,/home/ubuntu-20/anaconda3/envs/tensorflow/lib -Wl,-rpath-link,/home/ubuntu-20/anaconda3/envs/tensorflow/lib -L/home/ubuntu-20/anaconda3/envs/tensorflow/lib -L/home/ubuntu-20/anaconda3/envs/tensorflow/lib -Wl,-rpath,/home/ubuntu-20/anaconda3/envs/tensorflow/lib -Wl,-rpath-link,/home/ubuntu-20/anaconda3/envs/tensorflow/lib -L/home/ubuntu-20/anaconda3/envs/tensorflow/lib build/temp.linux-x86_64-3.9/../common/maskApi.o build/temp.linux-x86_64-3.9/pycocotools/_mask.o -o build/lib.linux-x86_64-3.9/pycocotools/_mask.cpython-39-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-3.9/pycocotools/_mask.cpython-39-x86_64-linux-gnu.so -> pycocotools\n",
      "rm -rf build\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6d18314",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -r pycocotools /home/ubuntu-20/Desktop/TensorFlow/models/research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f405a1",
   "metadata": {},
   "source": [
    "So,\"pycocotools\" library is installed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a4d7b",
   "metadata": {},
   "source": [
    "### Install the Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b39cf0",
   "metadata": {},
   "source": [
    "Now all the dependencies necessary for installing Object Detection API are done. So, we can install Object Detection API now. Object Detection API should be installed inside the **\"research\"** directory. Check the present current directory and go to the **\"research\"** directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7506c178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow/models/research/cocoapi/PythonAPI'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e97bebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-20/Desktop/TensorFlow/models/research/cocoapi\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82f29d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-20/Desktop/TensorFlow/models/research\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2909aa1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow/models/research'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf227d3",
   "metadata": {},
   "source": [
    "Next run the following two commands to install **\"Object Detection API\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99cf0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp object_detection/packages/tf2/setup.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a132da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/ubuntu-20/Desktop/TensorFlow/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "Collecting apache-beam\n",
      "  Downloading apache-beam-2.35.0.zip (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading Pillow-9.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 27.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lxml\n",
      "  Downloading lxml-4.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 20.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.2 MB 31.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Cython in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from object-detection==0.1) (0.29.26)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tf-slim\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 31.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from object-detection==0.1) (1.15.0)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 54.9 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lvis\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from object-detection==0.1) (1.6.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tf-models-official>=2.5.1\n",
      "  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 31.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow_io\n",
      "  Downloading tensorflow_io-0.23.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.1 MB 24.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 25.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 41.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 5.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.36.0-py2.py3-none-any.whl (8.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0 MB 27.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil>=5.4.3\n",
      "  Downloading psutil-5.9.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 24.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gin-config\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 1.3 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 32.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 8.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.15.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 28.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
      "\u001b[K     |████████████████████████████████| 213 kB 38.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 9.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.7 MB 25.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-text>=2.7.0\n",
      "  Downloading tensorflow_text-2.7.3-cp39-cp39-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 32.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow>=2.7.0\n",
      "  Downloading tensorflow-2.7.0-cp39-cp39-manylinux2010_x86_64.whl (489.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 489.7 MB 36 kB/s s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.2)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
      "\u001b[K     |████████████████████████████████| 661 kB 525 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.20.2-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 5.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.21.3)\n",
      "Collecting google-api-core<3.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-2.4.0-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 31.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-auth<3.0.0dev,>=1.16.0\n",
      "  Using cached google_auth-2.5.0-py2.py3-none-any.whl (157 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.27.1)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.54.0-py2.py3-none-any.whl (207 kB)\n",
      "\u001b[K     |████████████████████████████████| 207 kB 46.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (58.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.7)\n",
      "Requirement already satisfied: certifi in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 3.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: urllib3 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.25.11)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.10.0)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-2-py2.py3-none-manylinux1_x86_64.whl (13.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.3 MB 37.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard~=2.6 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "\u001b[K     |████████████████████████████████| 463 kB 36.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.42.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 31.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
      "Collecting google-auth<3.0.0dev,>=1.16.0\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 29.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Downloading dm_tree-0.1.6-cp39-cp39-manylinux_2_24_x86_64.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 3.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 7.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting orjson<4.0\n",
      "  Downloading orjson-3.6.6-cp39-cp39-manylinux_2_24_x86_64.whl (245 kB)\n",
      "\u001b[K     |████████████████████████████████| 245 kB 69.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 33.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
      "  Downloading fastavro-1.4.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 2.5 MB 22.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 4.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (516 kB)\n",
      "\u001b[K     |████████████████████████████████| 516 kB 40.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
      "  Downloading proto_plus-1.19.9-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 3.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow<7.0.0,>=0.15.1\n",
      "  Downloading pyarrow-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.6 MB 23.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 4.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.1.0\n",
      "  Downloading kiwisolver-1.3.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 48.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10.0\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Using cached opencv_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.4 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib->object-detection==0.1) (21.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.29.0-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.15.4\n",
      "  Downloading numpy-1.20.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.4 MB 22.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 6.7 MB/s  eta 0:00:011\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2022.1.18-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "\u001b[K     |████████████████████████████████| 763 kB 17.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Downloading scikit_learn-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.4 MB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 31.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.6.0-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 4.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 56.3 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: object-detection, kaggle, py-cpuinfo, apache-beam, crcmod, dill, avro-python3, docopt, pycocotools, seqeval, future, promise\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1651960 sha256=b4a770825456ecb980e9c1194be56efd5c7b82398e1ee141758090889036b201\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_lazcpli/wheels/39/13/de/7907e0ebd1103d93d3fbbf5800d2127ab2314a9468e208dd7d\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=11a9da565a8f68f81379a0ebf7562e418661845909e9b01ee3323f6cb4e36ddd\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/ac/b2/c3/fa4706d469b5879105991d1c8be9a3c2ef329ba9fe2ce5085e\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=480b6b4d0882ec3d7c8792187a30589cdddc9c2f33798bf4df11bda240dca83c\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/a9/33/c2/bcf6550ff9c95f699d7b2f261c8520b42b7f7c33b6e6920e29\n",
      "  Building wheel for apache-beam (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for apache-beam: filename=apache_beam-2.35.0-cp39-cp39-linux_x86_64.whl size=4559874 sha256=785b201cbc0b0006b772fb07a0f4704b9a479d0f24fc7c3362227910dfbf02a8\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/bd/f1/0a/5766032006be3a4bb638cabefcf84bd192a747f3ef2a48adbb\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp39-cp39-linux_x86_64.whl size=23681 sha256=a74f294bda1fac48d202425d751e863a3f667e4510f60ad5124a5868cbb4f71c\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/4a/6c/a6/ffdd136310039bf226f2707a9a8e6857be7d70a3fc061f6b36\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=25bb4c4730b62c27f2d0aacc663fffe214fb03bc0ac7e24b69b8dc65de7c67c3\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/4f/0b/ce/75d96dd714b15e51cb66db631183ea3844e0c4a6d19741a149\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=4239a0a07dc1701f14570d4f9d481bc2baf29fa4fc70eb64f9edb18fa6a7dda8\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/5a/29/4d/510c0e098c49c5e49519f430481a5425e60b8752682d7b1e55\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=cb7c111b7d9cabb89c247e06924c67af85cf484fea43dae60086e1c65e8be41d\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "  Building wheel for pycocotools (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp39-cp39-linux_x86_64.whl size=103609 sha256=128ef223cd1f8dd7b2fff6b1e1b4cd54b1a99ddf5201c08a93a32bb8fac06f2d\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/7e/b0/8e/f2c3593944ead79f5146d057d1310ee6d7b60d30b826779846\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=e018962b1ec240867d1922631f6ee71b91f50cc4f183d0e8fc3621333de08545\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=bfa636879c4c7ace4e73f9503f31a39fcbd5b6187317090d8579f13b0ee0c0ac\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/2f/a0/d3/4030d9f80e6b3be787f19fc911b8e7aa462986a40ab1e4bb94\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=a0b5ba58931c82628cff08098d31ee1fa7560da0a435ace40e10cd307e66942e\n",
      "  Stored in directory: /home/ubuntu-20/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "Successfully built object-detection kaggle py-cpuinfo apache-beam crcmod dill avro-python3 docopt pycocotools seqeval future promise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: google-auth, pyparsing, numpy, typing-extensions, threadpoolctl, text-unidecode, tensorflow-io-gcs-filesystem, tensorflow-estimator, pillow, libclang, kiwisolver, keras, joblib, httplib2, googleapis-common-protos, fonttools, cycler, uritemplate, typeguard, tqdm, tensorflow-metadata, tensorflow-hub, tensorflow, tabulate, scikit-learn, regex, pytz, python-slugify, promise, portalocker, matplotlib, google-auth-httplib2, google-api-core, future, docopt, dm-tree, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-datasets, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, pydot, pycocotools, pyarrow, py-cpuinfo, psutil, proto-plus, pandas, orjson, opencv-python-headless, opencv-python, oauth2client, kaggle, hdfs, google-api-python-client, gin-config, fastavro, crcmod, tf-models-official, tensorflow-io, lxml, lvis, contextlib2, avro-python3, apache-beam, object-detection\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.21.3\n",
      "    Uninstalling google-auth-1.21.3:\n",
      "      Successfully uninstalled google-auth-1.21.3\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.7\n",
      "    Uninstalling pyparsing-3.0.7:\n",
      "      Successfully uninstalled pyparsing-3.0.7\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "Successfully installed apache-beam-2.35.0 avro-python3-1.10.2 colorama-0.4.4 contextlib2-21.6.0 crcmod-1.7 cycler-0.11.0 dill-0.3.1.1 dm-tree-0.1.6 docopt-0.6.2 fastavro-1.4.9 fonttools-4.29.0 future-0.18.2 gin-config-0.5.0 google-api-core-2.4.0 google-api-python-client-2.36.0 google-auth-1.35.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.54.0 hdfs-2.6.0 httplib2-0.19.1 joblib-1.1.0 kaggle-1.5.12 keras-2.7.0 kiwisolver-1.3.2 libclang-12.0.0 lvis-0.5.3 lxml-4.7.1 matplotlib-3.5.1 numpy-1.20.3 oauth2client-4.1.3 object-detection-0.1 opencv-python-4.5.5.62 opencv-python-headless-4.5.5.62 orjson-3.6.6 pandas-1.4.0 pillow-9.0.0 portalocker-2.3.2 promise-2.3 proto-plus-1.19.9 psutil-5.9.0 py-cpuinfo-8.0.0 pyarrow-6.0.1 pycocotools-2.0.4 pydot-1.4.2 pymongo-3.12.3 pyparsing-2.4.7 python-slugify-5.0.2 pytz-2021.3 pyyaml-6.0 regex-2022.1.18 sacrebleu-2.0.0 scikit-learn-1.0.2 sentencepiece-0.1.96 seqeval-1.2.2 tabulate-0.8.9 tensorflow-2.7.0 tensorflow-addons-0.15.0 tensorflow-datasets-4.4.0 tensorflow-estimator-2.7.0 tensorflow-hub-0.12.0 tensorflow-io-0.23.1 tensorflow-io-gcs-filesystem-0.23.1 tensorflow-metadata-1.6.0 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 text-unidecode-1.3 tf-models-official-2.7.0 tf-slim-1.1.0 threadpoolctl-3.0.0 tqdm-4.62.3 typeguard-2.13.3 typing-extensions-3.10.0.2 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5176cdd9",
   "metadata": {},
   "source": [
    "Now object detection setup is done. You can verify the installation by executing the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a489c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26 14:06:57.624502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 14:06:57.627064: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2022-01-26 14:06:57.627577: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Running tests under Python 3.9.7: /home/ubuntu-20/anaconda3/envs/tensorflow/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-01-26 14:06:57.633834: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/builders/model_builder.py:1100: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0126 14:06:57.887338 139775303639424 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.43s\n",
      "I0126 14:06:58.056958 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.43s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.32s\n",
      "I0126 14:06:58.382251 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.32s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.18s\n",
      "I0126 14:06:58.560569 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.27s\n",
      "I0126 14:06:58.836110 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.27s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.94s\n",
      "I0126 14:07:00.775264 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.94s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0126 14:07:00.776373 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0126 14:07:00.794725 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0126 14:07:00.804883 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0126 14:07:00.815815 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "I0126 14:07:00.892999 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "I0126 14:07:00.975105 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "I0126 14:07:01.056505 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.07s\n",
      "I0126 14:07:01.129811 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.22s\n",
      "I0126 14:07:01.345800 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.22s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0126 14:07:01.367722 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0126 14:07:01.496387 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0126 14:07:01.496513 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0126 14:07:01.496586 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 3\n",
      "I0126 14:07:01.498541 139775303639424 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0126 14:07:01.511177 139775303639424 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0126 14:07:01.511280 139775303639424 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0126 14:07:01.567244 139775303639424 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0126 14:07:01.567365 139775303639424 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0126 14:07:01.709391 139775303639424 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0126 14:07:01.709509 139775303639424 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0126 14:07:01.866763 139775303639424 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0126 14:07:01.866876 139775303639424 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0126 14:07:02.097244 139775303639424 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0126 14:07:02.097411 139775303639424 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0126 14:07:02.300666 139775303639424 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0126 14:07:02.300801 139775303639424 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0126 14:07:02.603019 139775303639424 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0126 14:07:02.603131 139775303639424 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0126 14:07:02.672072 139775303639424 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0126 14:07:02.704981 139775303639424 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0126 14:07:02.740081 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0126 14:07:02.740202 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0126 14:07:02.740279 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 4\n",
      "I0126 14:07:02.741616 139775303639424 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0126 14:07:02.757367 139775303639424 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0126 14:07:02.757482 139775303639424 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0126 14:07:02.892325 139775303639424 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0126 14:07:02.892455 139775303639424 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0126 14:07:03.140067 139775303639424 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0126 14:07:03.140193 139775303639424 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0126 14:07:03.355316 139775303639424 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0126 14:07:03.355602 139775303639424 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0126 14:07:03.704387 139775303639424 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0126 14:07:03.704514 139775303639424 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0126 14:07:04.048340 139775303639424 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0126 14:07:04.048468 139775303639424 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0126 14:07:04.445351 139775303639424 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0126 14:07:04.445484 139775303639424 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0126 14:07:04.601372 139775303639424 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0126 14:07:04.637036 139775303639424 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0126 14:07:04.813985 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0126 14:07:04.814128 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0126 14:07:04.814162 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 5\n",
      "I0126 14:07:04.815535 139775303639424 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0126 14:07:04.835434 139775303639424 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0126 14:07:04.835582 139775303639424 efficientnet_model.py:147] round_filter input=16 output=16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0126 14:07:04.986997 139775303639424 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0126 14:07:04.987106 139775303639424 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0126 14:07:05.199536 139775303639424 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0126 14:07:05.199649 139775303639424 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 14:07:05.415032 139775303639424 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 14:07:05.415156 139775303639424 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0126 14:07:05.802588 139775303639424 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0126 14:07:05.802737 139775303639424 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0126 14:07:06.088043 139775303639424 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0126 14:07:06.088167 139775303639424 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0126 14:07:06.498754 139775303639424 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0126 14:07:06.498878 139775303639424 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0126 14:07:06.645416 139775303639424 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0126 14:07:06.686201 139775303639424 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0126 14:07:06.730251 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0126 14:07:06.730380 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0126 14:07:06.730456 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0126 14:07:06.731891 139775303639424 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0126 14:07:06.744326 139775303639424 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0126 14:07:06.744479 139775303639424 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 14:07:06.844000 139775303639424 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 14:07:06.844130 139775303639424 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 14:07:07.060233 139775303639424 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 14:07:07.060352 139775303639424 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 14:07:07.298660 139775303639424 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 14:07:07.298794 139775303639424 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0126 14:07:07.688406 139775303639424 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0126 14:07:07.688540 139775303639424 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0126 14:07:08.108583 139775303639424 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0126 14:07:08.108700 139775303639424 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0126 14:07:08.575955 139775303639424 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0126 14:07:08.576074 139775303639424 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0126 14:07:08.739605 139775303639424 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0126 14:07:08.774342 139775303639424 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0126 14:07:08.827544 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0126 14:07:08.827677 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0126 14:07:08.827760 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0126 14:07:08.829215 139775303639424 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0126 14:07:08.845425 139775303639424 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0126 14:07:08.845582 139775303639424 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 14:07:08.958070 139775303639424 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 14:07:08.958185 139775303639424 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 14:07:09.225388 139775303639424 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 14:07:09.225503 139775303639424 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0126 14:07:09.997115 139775303639424 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0126 14:07:09.997481 139775303639424 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0126 14:07:10.618946 139775303639424 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0126 14:07:10.619070 139775303639424 efficientnet_model.py:147] round_filter input=112 output=160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0126 14:07:11.172519 139775303639424 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0126 14:07:11.172716 139775303639424 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0126 14:07:11.924983 139775303639424 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0126 14:07:11.925154 139775303639424 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0126 14:07:12.110312 139775303639424 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0126 14:07:12.156013 139775303639424 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0126 14:07:12.216317 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0126 14:07:12.216438 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0126 14:07:12.216550 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0126 14:07:12.217988 139775303639424 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0126 14:07:12.233840 139775303639424 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0126 14:07:12.233994 139775303639424 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 14:07:12.442352 139775303639424 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 14:07:12.442608 139775303639424 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0126 14:07:12.901839 139775303639424 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0126 14:07:12.901962 139775303639424 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0126 14:07:13.358628 139775303639424 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0126 14:07:13.358763 139775303639424 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0126 14:07:13.977698 139775303639424 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0126 14:07:13.977850 139775303639424 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0126 14:07:14.595020 139775303639424 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0126 14:07:14.595132 139775303639424 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0126 14:07:15.408861 139775303639424 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0126 14:07:15.408992 139775303639424 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0126 14:07:15.911651 139775303639424 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0126 14:07:15.955137 139775303639424 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0126 14:07:16.027103 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0126 14:07:16.027235 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0126 14:07:16.027269 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0126 14:07:16.028584 139775303639424 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0126 14:07:16.044325 139775303639424 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0126 14:07:16.044440 139775303639424 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0126 14:07:16.250075 139775303639424 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0126 14:07:16.250248 139775303639424 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0126 14:07:16.787415 139775303639424 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0126 14:07:16.787561 139775303639424 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0126 14:07:17.292409 139775303639424 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0126 14:07:17.292533 139775303639424 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0126 14:07:18.011171 139775303639424 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0126 14:07:18.011286 139775303639424 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0126 14:07:18.725660 139775303639424 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0126 14:07:18.725782 139775303639424 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0126 14:07:19.761791 139775303639424 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0126 14:07:19.761954 139775303639424 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0126 14:07:20.048552 139775303639424 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0126 14:07:20.091845 139775303639424 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0126 14:07:20.166972 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0126 14:07:20.167091 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0126 14:07:20.167124 139775303639424 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0126 14:07:20.168422 139775303639424 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0126 14:07:20.185153 139775303639424 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0126 14:07:20.185356 139775303639424 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0126 14:07:20.498679 139775303639424 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0126 14:07:20.498799 139775303639424 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0126 14:07:21.150535 139775303639424 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0126 14:07:21.150656 139775303639424 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0126 14:07:22.106084 139775303639424 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0126 14:07:22.106252 139775303639424 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0126 14:07:23.065239 139775303639424 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0126 14:07:23.065360 139775303639424 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0126 14:07:23.981920 139775303639424 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0126 14:07:23.982052 139775303639424 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0126 14:07:25.154724 139775303639424 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0126 14:07:25.154839 139775303639424 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0126 14:07:25.557402 139775303639424 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0126 14:07:25.597800 139775303639424 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.32s\n",
      "I0126 14:07:25.692402 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.32s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0126 14:07:25.702633 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0126 14:07:25.704203 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0126 14:07:25.704608 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0126 14:07:25.705996 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0126 14:07:25.707099 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0126 14:07:25.707320 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0126 14:07:25.708297 139775303639424 test_util.py:2308] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 28.079s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67840aaf",
   "metadata": {},
   "source": [
    "## Train Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f63263",
   "metadata": {},
   "source": [
    "To train an Object Detection model, we need some assets like some images for both train and test, image annotations, pre-trained object detection model, trained resources, and exported model to use for prediction. To keep things clear I create some directories. All the new folders are created inside the named **\"training_demo\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f3c51d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow/models/research'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e13f6",
   "metadata": {},
   "source": [
    "**\"training_demo\"** for organizing all the resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "980f233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../training_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f95f70",
   "metadata": {},
   "source": [
    "**\"annotations\"** for \".record\" and \".pbtxt\" files. \".record\" files are used as annotations and \".pbtxt\" file for class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f0f33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../training_demo/annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a1b89",
   "metadata": {},
   "source": [
    "**\"exported-models\"** for final exported models. This model (.pb file and .config file is used for final prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a537dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../training_demo/exported-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0467900",
   "metadata": {},
   "source": [
    "**\"images\"** folder for store train and validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae52959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../training_demo/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e3aef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../training_demo/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce55c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../training_demo/images/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a678a",
   "metadata": {},
   "source": [
    "**\"models\"** directory to store models and training informations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71759106",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../training_demo/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ec111",
   "metadata": {},
   "source": [
    "**\"pre-trained-models\"** for storing \"pre-trained-models\" models. in our case \"efficientdetD3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b106c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../training_demo/pre-trained-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fb63cc",
   "metadata": {},
   "source": [
    "### Download pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8106e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow/models/research'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a2a72",
   "metadata": {},
   "source": [
    "change directory to \"pre-trained-models\" (which I create earlier). Then downlaod pre-train model from tensorflow model zoo. To download any model go to this [GitHub repo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Copy any model's link address and download it using wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e00c0d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-20/Desktop/TensorFlow/training_demo/pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "cd ../../training_demo/pre-trained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9782f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow/training_demo/pre-trained-models'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15fcfa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-26 16:12:25--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d3_coco17_tpu-32.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 2404:6800:4004:810::2010, 172.217.174.112\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|2404:6800:4004:810::2010|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 92858658 (89M) [application/x-tar]\n",
      "Saving to: ‘efficientdet_d3_coco17_tpu-32.tar.gz’\n",
      "\n",
      "efficientdet_d3_coc 100%[===================>]  88.56M  27.6MB/s    in 3.5s    \n",
      "\n",
      "2022-01-26 16:12:29 (25.6 MB/s) - ‘efficientdet_d3_coco17_tpu-32.tar.gz’ saved [92858658/92858658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d3_coco17_tpu-32.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0155354",
   "metadata": {},
   "source": [
    "unpack downloaded model inside \"pre-trained-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf77a86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientdet_d3_coco17_tpu-32/\n",
      "efficientdet_d3_coco17_tpu-32/checkpoint/\n",
      "efficientdet_d3_coco17_tpu-32/checkpoint/ckpt-0.data-00000-of-00001\n",
      "efficientdet_d3_coco17_tpu-32/checkpoint/checkpoint\n",
      "efficientdet_d3_coco17_tpu-32/checkpoint/ckpt-0.index\n",
      "efficientdet_d3_coco17_tpu-32/pipeline.config\n",
      "efficientdet_d3_coco17_tpu-32/saved_model/\n",
      "efficientdet_d3_coco17_tpu-32/saved_model/saved_model.pb\n",
      "efficientdet_d3_coco17_tpu-32/saved_model/assets/\n",
      "efficientdet_d3_coco17_tpu-32/saved_model/variables/\n",
      "efficientdet_d3_coco17_tpu-32/saved_model/variables/variables.data-00000-of-00001\n",
      "efficientdet_d3_coco17_tpu-32/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf efficientdet_d3_coco17_tpu-32.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8b8b199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow/training_demo/pre-trained-models'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dda5a7",
   "metadata": {},
   "source": [
    "### Generate .record file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9abdaae",
   "metadata": {},
   "source": [
    "Now we have a pre-trained model. Let's create training and test files. We have some training images along with annotation XML files both in the train and test folder. There is a **\"generate_tfrecord.py\"** file inside the \"training_demo\" folder. This file can be used to generate train and test the \".record\" file.<br>\n",
    "\n",
    "simply call \"generate_tfrecord.py\" and pass train images folder path, label_map.pbtxt file path, and directory path to save train.record file path. Paths can be anywhere. it completely depends on you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8deea7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-20/Desktop/TensorFlow/training_demo\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98114cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: annotations/train.record\n",
      "Successfully created the TFRecord file: annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "# Create train data:\n",
    "!python generate_tfrecord.py -x images/train -l annotations/label_map.pbtxt -o annotations/train.record\n",
    "\n",
    "#Create test data:\n",
    "!python generate_tfrecord.py -x images/test -l annotations/label_map.pbtxt -o annotations/test.record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1e8092",
   "metadata": {},
   "source": [
    "Now we have necessary training files (train.record, test.record and label_map.pbtxt)and necessary pre-traind models. One last thing is needed is to configer **\"pipeline.config\"** file. Inside this file we have to configer\n",
    "\n",
    "- train.record file path\n",
    "- test.record file path\n",
    "- label_map.pbtxt file path\n",
    "- batch_size\n",
    "- number of classes\n",
    "- fine_tune_checkpoint_type\n",
    "- use_bfloat16\n",
    "- fine_tune_checkpoint_type\n",
    "\n",
    "You can find \"pipeline.config\" file inside the downloaded pre-trained model folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978862d0",
   "metadata": {},
   "source": [
    "To make everything clean and reusable, I coppied the \"pipeline.config\" file from \"pre-trained-models/efficientdet_d3_coco17_tpu-32\" to \"exported_models/efficientdet\" folder and edit it. Open \"pipeline.config\" and searche for \n",
    "1. num_classes\n",
    "<pre>As we are focusing just on finding the object, our number of classes is 1. Now change num_classes to 1.</pre>\n",
    "2. batch_size\n",
    "<pre>Depending of the GPU, we can use any batch size. So use any number suitable for the training</pre>\n",
    "3. total_steps/num_steps\n",
    "<pre>Defines how long we like to train the model. Note that total_steps & num_steps are two different parameters. You have to assign the same value for both of them. Another important point is \"warmup_steps\". Both total_steps & num_steps must be higher than warmup_steps. Otherwise, you will get some errors.</pre>\n",
    "4. fine_tune_checkpoint\n",
    "<pre>You may find it just before the \"num_steps\" parameter. Basically, you have to specify the downloaded pre-trained model's checkpoint path to start training using that pre-trained model. Currently, we are using efficientdetD3. So, go to the pre-trained-models -> efficientdet_d3_coco17_tpu-32 -> checkpoint folder  and copy the relative path of \"ckpt-0.index\" and paste it here. As I am currently inside \"training_demo\" folder, so relative path from \"training_demo\" would be \"./pre-trained-models/efficientdet_d3_coco17_tpu-32/checkpoint/ckpt-0\". <strong>Note that, you have to remove the extension from \"ckpt-0.index\" file</strong>. The model already knows the file extension. <strong>BTW, all folder names are changeable. If you want to change the folder name or path, you can do that. Just make sure to specify the file path correctly</strong></pre>\n",
    "5. fine_tune_checkpoint_type\n",
    "<pre>Change fine_tune_checkpoint_type to <strong>\"detection\"</strong> as we are trying to detect objects.</pre>\n",
    "6. use_bfloat16\n",
    "<pre>Change \"use_bfloat16\" to <strong>flase</strong> as we are not using TPU's</pre>\n",
    "7. train_input_reader\n",
    "<pre>Inside \"train_input_reader\" section, you have to modify 2 parameters, \"label_map_path\" & \"input_path\".  The \"label_map.pbtxt\" can be found inside \"annotations\" folder (as i put it there. You can put it anywhere you like). As we are still inside \"training_demo\" folder, so relative path would be \"./annotations/label_map.pbtxt\".<br>\n",
    "Next \"input_path\". As this \"input_path\" is inside \"train_input_reader\" section, so we have to specify traing input file which is <strong>train.record</strong> file. The \"train.record\" file can also be found inside \"annotations\" folder. As we are still inside \"training_demo\" folder, so relative path would be \"./annotations/train.record\".</pre>\n",
    "\n",
    "8. eval_input_reader\n",
    "<pre>Inside \"eval_input_reader\" section, you also have to modify 2 parameters, \"label_map_path\" & \"input_path\".  The \"label_map.pbtxt\" can be found inside \"annotations\" folder (as i put it there. You can put it anywhere you like). As we are still inside \"training_demo\" folder, so relative path would be \"./annotations/label_map.pbtxt\".<br>\n",
    "Next \"input_path\". As this \"input_path\" is inside the \"eval_input_reader\" section, so we have to specify the training input file which is <strong>test.record</strong> file (I named validation set as test. You can use val or validation. Just make sure to change the path accordingly). The \"test.record\" file can also be found inside the \"annotations\" folder. As we are still inside the \"training_demo\" folder, so the relative path would be \"./annotations/test.record\".</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be78e9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7920e3",
   "metadata": {},
   "source": [
    "Now we are done with all installation and configurations. Let's train the model. Currently we are inside **\"training_demo\"** folder. If you check, you will find a file named **\"model_main_tf2.py\"**. This is the file we are going to use to train the object detection model. This file is also provided by Tensorflow. Check out this file. There are also some configurations inside this file. You can change/pass the argument depending on your objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d47b603c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow/training_demo'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec731e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  model_main_tf2.py\r\n",
      "\u001b[01;34mexported-models\u001b[0m/     generate_tfrecord.py        \u001b[01;34mmodels\u001b[0m/\r\n",
      "exporter_main_v2.py  \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a24487",
   "metadata": {},
   "source": [
    "To train the model, you have to pass two parameters, **\"model_dir\"** & **\"pipeline_config_path\"**. \"model_dir\" is the folder where you want to save your model training progress (this folder will be needed later for visualization of the training graphs) and \"pipeline_config_path\" is the folder where we want to save our trained model configuration. (Basically, the configuration file which will be saved in this training process is the same one we configured earlier. Just to make this separate, I saved this config file in the same folder where the trained models are going to save). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d03ca539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26 19:18:16.924165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 19:18:16.927108: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64\n",
      "2022-01-26 19:18:16.927694: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-26 19:18:16.928442: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0126 19:18:16.930691 139684560966016 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0126 19:18:16.931914 139684560966016 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0126 19:18:16.935007 139684560966016 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0126 19:18:16.935164 139684560966016 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "I0126 19:18:16.944221 139684560966016 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0126 19:18:16.944335 139684560966016 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0126 19:18:16.944365 139684560966016 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0126 19:18:16.947594 139684560966016 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0126 19:18:16.979430 139684560966016 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0126 19:18:16.979545 139684560966016 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 19:18:17.123809 139684560966016 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 19:18:17.123928 139684560966016 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 19:18:17.395811 139684560966016 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 19:18:17.395925 139684560966016 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 19:18:17.663366 139684560966016 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 19:18:17.663570 139684560966016 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0126 19:18:18.200055 139684560966016 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0126 19:18:18.200171 139684560966016 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0126 19:18:18.719847 139684560966016 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0126 19:18:18.719960 139684560966016 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0126 19:18:19.291749 139684560966016 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0126 19:18:19.291912 139684560966016 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0126 19:18:19.552504 139684560966016 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0126 19:18:19.620378 139684560966016 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0126 19:18:19.679734 139684560966016 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['./annotations/train.record']\n",
      "I0126 19:18:19.692135 139684560966016 dataset_builder.py:163] Reading unweighted datasets: ['./annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['./annotations/train.record']\n",
      "I0126 19:18:19.692332 139684560966016 dataset_builder.py:80] Reading record datasets for input file: ['./annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0126 19:18:19.692425 139684560966016 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0126 19:18:19.692487 139684560966016 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0126 19:18:19.694516 139684560966016 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0126 19:18:19.851195 139684560966016 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0126 19:18:24.580934 139684560966016 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0126 19:18:27.232981 139684560966016 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2022-01-26 19:18:29.275193: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-01-26 19:18:29.802818: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n",
      "/home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0126 19:18:58.426820 139676748863232 deprecation.py:545] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "W0126 19:19:06.249039 139676748863232 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "W0126 19:19:17.842705 139676748863232 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "W0126 19:19:27.477190 139676748863232 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "W0126 19:19:38.556267 139676748863232 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "INFO:tensorflow:Step 100 per-step time 6.912s\n",
      "I0126 19:30:29.503887 139684560966016 model_lib_v2.py:705] Step 100 per-step time 6.912s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 2.3749464,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.038565468,\n",
      " 'Loss/total_loss': 2.4135118,\n",
      " 'learning_rate': 0.0}\n",
      "I0126 19:30:29.526928 139684560966016 model_lib_v2.py:708] {'Loss/classification_loss': 2.3749464,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.038565468,\n",
      " 'Loss/total_loss': 2.4135118,\n",
      " 'learning_rate': 0.0}\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=models/EfficientDet-D3-custom-trained --pipeline_config_path=models/EfficientDet-D3-custom-trained/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d65cb",
   "metadata": {},
   "source": [
    "If you to train on multiple GPU, then you have to add **\"num_clones\"**. \"num_clones\" defines how many GPUs you like to use. I have only 1 GPU. So i assign **--num_clones=1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5106a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26 19:51:11.329579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 19:51:11.332355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64\n",
      "2022-01-26 19:51:11.332701: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-26 19:51:11.333297: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0126 19:51:11.335279 140671546012032 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0126 19:51:11.336194 140671546012032 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0126 19:51:11.338904 140671546012032 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0126 19:51:11.339073 140671546012032 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "I0126 19:51:11.347533 140671546012032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0126 19:51:11.347657 140671546012032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0126 19:51:11.347728 140671546012032 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0126 19:51:11.350413 140671546012032 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0126 19:51:11.381894 140671546012032 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0126 19:51:11.382004 140671546012032 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 19:51:11.517031 140671546012032 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 19:51:11.517138 140671546012032 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 19:51:11.772451 140671546012032 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 19:51:11.772562 140671546012032 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 19:51:12.061040 140671546012032 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 19:51:12.061159 140671546012032 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0126 19:51:12.604596 140671546012032 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0126 19:51:12.604715 140671546012032 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0126 19:51:13.175338 140671546012032 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0126 19:51:13.175463 140671546012032 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0126 19:51:13.943156 140671546012032 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0126 19:51:13.943384 140671546012032 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0126 19:51:14.294837 140671546012032 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0126 19:51:14.345150 140671546012032 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0126 19:51:14.389445 140671546012032 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['./annotations/train.record']\n",
      "I0126 19:51:14.401006 140671546012032 dataset_builder.py:163] Reading unweighted datasets: ['./annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['./annotations/train.record']\n",
      "I0126 19:51:14.401212 140671546012032 dataset_builder.py:80] Reading record datasets for input file: ['./annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0126 19:51:14.401286 140671546012032 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0126 19:51:14.401366 140671546012032 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0126 19:51:14.403273 140671546012032 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0126 19:51:14.562267 140671546012032 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0126 19:51:19.616015 140671546012032 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0126 19:51:22.496867 140671546012032 deprecation.py:341] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2022-01-26 19:51:24.571085: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "/home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0126 19:51:55.055413 140663467276032 deprecation.py:545] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "W0126 19:52:03.805298 140663467276032 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "W0126 19:52:17.698312 140663467276032 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "W0126 19:52:28.856673 140663467276032 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "W0126 19:52:40.214063 140663467276032 utils.py:76] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "INFO:tensorflow:Step 100 per-step time 6.888s\n",
      "I0126 20:03:23.654749 140671546012032 model_lib_v2.py:705] Step 100 per-step time 6.888s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 1.0755744,\n",
      " 'Loss/localization_loss': 0.024037467,\n",
      " 'Loss/regularization_loss': 0.038565367,\n",
      " 'Loss/total_loss': 1.1381773,\n",
      " 'learning_rate': 0.0}\n",
      "I0126 20:03:23.673841 140671546012032 model_lib_v2.py:708] {'Loss/classification_loss': 1.0755744,\n",
      " 'Loss/localization_loss': 0.024037467,\n",
      " 'Loss/regularization_loss': 0.038565367,\n",
      " 'Loss/total_loss': 1.1381773,\n",
      " 'learning_rate': 0.0}\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py  --model_dir=models/EfficientDet-D3-custom-trained --pipeline_config_path=models/EfficientDet-D3-custom-trained/pipeline.config --num_clones=1 --ps_tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58dae8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu-20/Desktop/TensorFlow/training_demo'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59af652",
   "metadata": {},
   "source": [
    "# Visualizing the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782dc28e",
   "metadata": {},
   "source": [
    "Tensorflow has a nice tool to visulize the praining progress named \"Tensorbord\". This tool is automatically installed when you install tensorflow using the conda comand. To visulize training progress: <br>\n",
    "\n",
    "- Open a new terminal.\n",
    "- activate the virtual environment by trping **source activate tensorflow** (which we have done before in a different terminal)\n",
    "- navigate to **\"training_demo\"** folder\n",
    "- now type **tensorboard --logdir=models/EfficientDet-D3-custom-trained** as we saved our trained network in \"EfficientDet-D3-custom-trained\" folder.\n",
    "\n",
    "Once this is done, terminal will show you something like this **\"TensorBoard 2.6.0 at http://localhost:6006/ (Press CTRL+C to quit)\"**<br>\n",
    "\n",
    "Go to **http://localhost:6006/** and you can see different graphs related to your training progress.(Port number might be different)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee3c8e",
   "metadata": {},
   "source": [
    "# Export the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb891969",
   "metadata": {},
   "source": [
    "We already trained our model. But Tensorflow Object Detection API didn't save the final model. Instead, it saves the checkpoints after every 1000 steps(you can change this step number from model_main_tf2.py). Now we have to export the final model from these checkpoints. <br> <br>\n",
    "**Note:** the benefit of having these checkpoint files is, you can restart your training process from any of these checkpoint files later if you want.<br><br>\n",
    "Now to export the final model, we will use \"exporter_main_v2.py\". This file is also provided by Tensorflow.<br><br>\n",
    "\n",
    "Execute the following command with appropriate parameters. We already discussed all the folders necessary for this command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69abae5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26 19:38:08.131745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 19:38:08.134366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2022-01-26 19:38:08.134966: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-26 19:38:08.140429: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0126 19:38:08.147075 140401355592064 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0126 19:38:08.147200 140401355592064 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0126 19:38:08.147293 140401355592064 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0126 19:38:08.150027 140401355592064 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0126 19:38:08.166386 140401355592064 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0126 19:38:08.166506 140401355592064 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 19:38:08.273832 140401355592064 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0126 19:38:08.273949 140401355592064 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 19:38:08.459990 140401355592064 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0126 19:38:08.460103 140401355592064 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 19:38:08.650922 140401355592064 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0126 19:38:08.651039 140401355592064 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0126 19:38:08.969503 140401355592064 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0126 19:38:08.969624 140401355592064 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0126 19:38:09.477416 140401355592064 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0126 19:38:09.477530 140401355592064 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0126 19:38:09.952585 140401355592064 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0126 19:38:09.952699 140401355592064 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0126 19:38:10.110199 140401355592064 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0126 19:38:10.148629 140401355592064 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "WARNING:tensorflow:From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0126 19:38:13.148314 140401355592064 deprecation.py:614] From /home/ubuntu-20/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb13074bca0>, because it is not built.\n",
      "W0126 19:38:28.202083 140401355592064 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb13074bca0>, because it is not built.\n",
      "2022-01-26 19:38:59.669341: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0126 19:39:36.125263 140401355592064 save.py:263] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 1315). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: exported_models/efficientdet/saved_model/assets\n",
      "I0126 19:39:58.307252 140401355592064 builder_impl.py:783] Assets written to: exported_models/efficientdet/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to exported_models/efficientdet/pipeline.config\n",
      "I0126 19:39:59.810654 140401355592064 config_util.py:253] Writing pipeline config file to exported_models/efficientdet/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path models/EfficientDet-D3-custom-trained/pipeline.config --trained_checkpoint_dir models/EfficientDet-D3-custom-trained --output_directory exported_models/efficientdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea29e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
